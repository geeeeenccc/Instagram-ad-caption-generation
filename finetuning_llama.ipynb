{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning LLaMA Model"
      ],
      "metadata": {
        "id": "nH85Cs7s1VL1"
      },
      "id": "nH85Cs7s1VL1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68e048b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:51:25.024678Z",
          "iopub.status.busy": "2024-05-23T12:51:25.024299Z",
          "iopub.status.idle": "2024-05-23T12:55:14.479724Z",
          "shell.execute_reply": "2024-05-23T12:55:14.478414Z"
        },
        "id": "a68e048b",
        "outputId": "b2caa01b-d2e8-49a7-8c64-aeea4e5c53c0",
        "papermill": {
          "duration": 229.502314,
          "end_time": "2024-05-23T12:55:14.482121",
          "exception": false,
          "start_time": "2024-05-23T12:51:24.979807",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "kaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.32.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\r\n",
            "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
            "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
            "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\r\n",
            "pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq torch==2.0.1 --progress-bar off\n",
        "!pip install -qqq transformers==4.32.1 --progress-bar off\n",
        "!pip install -qqq datasets==2.14.4 --progress-bar off\n",
        "!pip install -qqq peft==0.5.0 --progress-bar off\n",
        "!pip install -qqq bitsandbytes==0.41.1 --progress-bar off\n",
        "!pip install -qqq trl==0.7.1 --progress-bar off"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "iEawFVQb1YcX"
      },
      "id": "iEawFVQb1YcX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba470fc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:14.571540Z",
          "iopub.status.busy": "2024-05-23T12:55:14.571149Z",
          "iopub.status.idle": "2024-05-23T12:55:31.462142Z",
          "shell.execute_reply": "2024-05-23T12:55:31.461161Z"
        },
        "id": "9ba470fc",
        "papermill": {
          "duration": 16.938271,
          "end_time": "2024-05-23T12:55:31.464564",
          "exception": false,
          "start_time": "2024-05-23T12:55:14.526293",
          "status": "completed"
        },
        "tags": [],
        "outputId": "92f7e436-740a-4d32-9694-9a74dbf0811d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-23 12:55:23.097308: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-23 12:55:23.097445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-23 12:55:23.241032: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import notebook_login, login\n",
        "from peft import LoraConfig, PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3452330",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:31.552928Z",
          "iopub.status.busy": "2024-05-23T12:55:31.552048Z",
          "iopub.status.idle": "2024-05-23T12:55:31.559778Z",
          "shell.execute_reply": "2024-05-23T12:55:31.558868Z"
        },
        "id": "a3452330",
        "outputId": "2bcd5118-1b77-42db-d74f-60345373c885",
        "papermill": {
          "duration": 0.053231,
          "end_time": "2024-05-23T12:55:31.561725",
          "exception": false,
          "start_time": "2024-05-23T12:55:31.508494",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "938e8e2b",
      "metadata": {
        "id": "938e8e2b",
        "papermill": {
          "duration": 0.043009,
          "end_time": "2024-05-23T12:55:31.647604",
          "exception": false,
          "start_time": "2024-05-23T12:55:31.604595",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load and Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b20c2e3b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:31.733477Z",
          "iopub.status.busy": "2024-05-23T12:55:31.733130Z",
          "iopub.status.idle": "2024-05-23T12:55:32.590283Z",
          "shell.execute_reply": "2024-05-23T12:55:32.589472Z"
        },
        "id": "b20c2e3b",
        "papermill": {
          "duration": 0.902852,
          "end_time": "2024-05-23T12:55:32.592783",
          "exception": false,
          "start_time": "2024-05-23T12:55:31.689931",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "file_path = '/kaggle/input/instagram-ads/instagram_posts.json'\n",
        "df = pd.read_json(file_path)\n",
        "\n",
        "# Convert the DataFrame to a Hugging Face dataset\n",
        "dataset = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c08e13",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:32.686049Z",
          "iopub.status.busy": "2024-05-23T12:55:32.685394Z",
          "iopub.status.idle": "2024-05-23T12:55:32.690920Z",
          "shell.execute_reply": "2024-05-23T12:55:32.689945Z"
        },
        "id": "d6c08e13",
        "papermill": {
          "duration": 0.053613,
          "end_time": "2024-05-23T12:55:32.693180",
          "exception": false,
          "start_time": "2024-05-23T12:55:32.639567",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
        "Write an engaging Instagram post caption about the given input. You can generate a few heashtags.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_training_prompt(conversation: str, summary: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
        "    return f\"\"\"### Instruction: {system_prompt}\n",
        "\n",
        "### Input:\n",
        "{conversation.strip()}\n",
        "\n",
        "### Response:\n",
        "{summary}\n",
        "\"\"\".strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd1ff6f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:32.882526Z",
          "iopub.status.busy": "2024-05-23T12:55:32.881973Z",
          "iopub.status.idle": "2024-05-23T12:55:32.887145Z",
          "shell.execute_reply": "2024-05-23T12:55:32.886217Z"
        },
        "id": "0cd1ff6f",
        "papermill": {
          "duration": 0.051549,
          "end_time": "2024-05-23T12:55:32.889297",
          "exception": false,
          "start_time": "2024-05-23T12:55:32.837748",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Function to clean the text in the dataset\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = re.sub(r\"http\\S+\", \"\", text)\n",
        "        text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
        "        text = re.sub(r\"\\s+\", \" \", text)\n",
        "        return re.sub(r\"\\^[^ ]+\", \"\", text)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# Function to create the ad text\n",
        "def create_ad_text(data_point):\n",
        "    caption = clean_text(data_point[\"caption\"])\n",
        "    # return f\"Check out our latest post: {caption}\"\n",
        "    return caption\n",
        "\n",
        "# Function to generate the text from the data point\n",
        "def generate_text(data_point):\n",
        "    ad_text = create_ad_text(data_point)\n",
        "    return {\n",
        "        \"ad_text\": ad_text\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5347b081",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:33.021990Z",
          "iopub.status.busy": "2024-05-23T12:55:33.021616Z",
          "iopub.status.idle": "2024-05-23T12:55:33.034586Z",
          "shell.execute_reply": "2024-05-23T12:55:33.033858Z"
        },
        "id": "5347b081",
        "papermill": {
          "duration": 0.103709,
          "end_time": "2024-05-23T12:55:33.036436",
          "exception": false,
          "start_time": "2024-05-23T12:55:32.932727",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Example data point\n",
        "example = generate_text(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a05b142b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:33.127310Z",
          "iopub.status.busy": "2024-05-23T12:55:33.126948Z",
          "iopub.status.idle": "2024-05-23T12:55:33.133634Z",
          "shell.execute_reply": "2024-05-23T12:55:33.132729Z"
        },
        "id": "a05b142b",
        "papermill": {
          "duration": 0.054576,
          "end_time": "2024-05-23T12:55:33.135613",
          "exception": false,
          "start_time": "2024-05-23T12:55:33.081037",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Function to process dataset\n",
        "def process_dataset(data: Dataset):\n",
        "    return (\n",
        "        data.shuffle(seed=42)\n",
        "        .map(generate_text)\n",
        "        .remove_columns(['id', 'shortCode', 'caption', 'hashtags', 'mentions',\n",
        "                'url', 'commentsCount', 'firstComment', 'latestComments',\n",
        "                'dimensionsHeight', 'dimensionsWidth', 'displayUrl',\n",
        "                'images', 'videoUrl', 'alt', 'likesCount', 'videoViewCount',\n",
        "                'videoPlayCount', 'timestamp', 'childPosts', 'ownerFullName',\n",
        "                'ownerUsername', 'ownerId', 'productType', 'videoDuration',\n",
        "                'isSponsored', 'isPinned', 'musicInfo', 'taggedUsers',\n",
        "                'coauthorProducers', 'locationName', 'locationId', 'error',\n",
        "                'description', 'paidPartnership', 'sponsors'])\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbba3554",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:33.224011Z",
          "iopub.status.busy": "2024-05-23T12:55:33.223678Z",
          "iopub.status.idle": "2024-05-23T12:55:33.229794Z",
          "shell.execute_reply": "2024-05-23T12:55:33.228835Z"
        },
        "id": "bbba3554",
        "outputId": "d1601422-81e1-408b-b056-7d22956cea9c",
        "papermill": {
          "duration": 0.051883,
          "end_time": "2024-05-23T12:55:33.231779",
          "exception": false,
          "start_time": "2024-05-23T12:55:33.179896",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['inputUrl', 'id', 'type', 'shortCode', 'caption', 'hashtags', 'mentions', 'url', 'commentsCount', 'firstComment', 'latestComments', 'dimensionsHeight', 'dimensionsWidth', 'displayUrl', 'images', 'videoUrl', 'alt', 'likesCount', 'videoViewCount', 'videoPlayCount', 'timestamp', 'childPosts', 'ownerFullName', 'ownerUsername', 'ownerId', 'productType', 'videoDuration', 'isSponsored', 'isPinned', 'musicInfo', 'taggedUsers', 'coauthorProducers', 'locationName', 'locationId', 'error', 'description', 'paidPartnership', 'sponsors'],\n",
              "    num_rows: 2800\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd43b4a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:33.320122Z",
          "iopub.status.busy": "2024-05-23T12:55:33.319529Z",
          "iopub.status.idle": "2024-05-23T12:55:35.920770Z",
          "shell.execute_reply": "2024-05-23T12:55:35.919837Z"
        },
        "id": "4dd43b4a",
        "outputId": "e2d5b503-3e28-41b0-904d-5cf9a18b42eb",
        "papermill": {
          "duration": 2.64763,
          "end_time": "2024-05-23T12:55:35.922866",
          "exception": false,
          "start_time": "2024-05-23T12:55:33.275236",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "cbcc61a2afdb41ce8ff169be178ccf10"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbcc61a2afdb41ce8ff169be178ccf10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = process_dataset(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8109b69",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:36.011040Z",
          "iopub.status.busy": "2024-05-23T12:55:36.010415Z",
          "iopub.status.idle": "2024-05-23T12:55:36.016179Z",
          "shell.execute_reply": "2024-05-23T12:55:36.015317Z"
        },
        "id": "e8109b69",
        "outputId": "79e21f9b-166e-4c4e-9205-00c6ebf88999",
        "papermill": {
          "duration": 0.051925,
          "end_time": "2024-05-23T12:55:36.018152",
          "exception": false,
          "start_time": "2024-05-23T12:55:35.966227",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['inputUrl', 'type', 'ad_text'],\n",
              "    num_rows: 2800\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "057f781b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:36.105954Z",
          "iopub.status.busy": "2024-05-23T12:55:36.105634Z",
          "iopub.status.idle": "2024-05-23T12:55:36.118553Z",
          "shell.execute_reply": "2024-05-23T12:55:36.117659Z"
        },
        "id": "057f781b",
        "outputId": "c0d96c5f-e846-4f3c-eb3b-fbd199804982",
        "papermill": {
          "duration": 0.059438,
          "end_time": "2024-05-23T12:55:36.120304",
          "exception": false,
          "start_time": "2024-05-23T12:55:36.060866",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['These guys get it.',\n",
              " 'Balloon sleeves + bermuda shorts? SO refreshing🚰 #SpringLightly',\n",
              " 'Let’t Go!!! 🔥 #brklnbloke #blackfriday #blackfridaysale #blackfridaydeals #holidayshopping',\n",
              " 'The multi-sport quiver-killer has done it again. With a lighter-than-ever design, more comprehensive fit and an additional volume, the Talon™/Tempest Pro is ready to tackle your most ambitious adventures. #OspreyPacks',\n",
              " 'We asked — beauty expert, travel aficionado, and hosting queen — from Instagram’s partnerships team what gifts from emerging brands she thinks are worth giving this year. Swipe through for her picks from a travel-friendly skincare set to an unexpected little luxury you probably wouldn’t buy for yourself. 🌟',\n",
              " 'TODAY!! SAGE🌿RESTOCK NOON ET 🛒 SHOP.TELFAR.NET + EU.TELFAR.NET',\n",
              " '*Immediately adds VS Archives Swim to our vacation moodboard* #VSEscapetoSummer',\n",
              " '1 extra large latte and this ‘fit on repeat please. [she/her] #asseenonme Weekday ruched mini skirt [134463000] ASOS DESIGN baby tee [134101080]',\n",
              " 'Show up and show off to the office with a pop of color #Everlane #ElevatedOuterwear #PopOfColor',\n",
              " 'OUT NOW: Matte Green Ceramics The world of MVMT Advanced Ceramic timekeeping keeps breaking new ground. Meet the Matte Green Ceramic pigment, a finish so rich it could only be achieved by meticulously diamond-blasting our highly technical ceramic material. This distinct tone is inspired by tactical gear and the wilds they’ve explored. #jointhemvmt #ceramic #ceramicwatch (📷:']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['ad_text'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split and process train and validation datasets"
      ],
      "metadata": {
        "id": "rzpIiF_L19MS"
      },
      "id": "rzpIiF_L19MS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b84675",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:36.211100Z",
          "iopub.status.busy": "2024-05-23T12:55:36.210248Z",
          "iopub.status.idle": "2024-05-23T12:55:36.214906Z",
          "shell.execute_reply": "2024-05-23T12:55:36.214068Z"
        },
        "id": "a3b84675",
        "papermill": {
          "duration": 0.052774,
          "end_time": "2024-05-23T12:55:36.216749",
          "exception": false,
          "start_time": "2024-05-23T12:55:36.163975",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and validation sets\n",
        "train_test_ratio = 0.92\n",
        "train_size = int(train_test_ratio * len(dataset))\n",
        "val_size = len(dataset) - train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f75a603",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:36.304686Z",
          "iopub.status.busy": "2024-05-23T12:55:36.304290Z",
          "iopub.status.idle": "2024-05-23T12:55:36.320242Z",
          "shell.execute_reply": "2024-05-23T12:55:36.319349Z"
        },
        "id": "0f75a603",
        "papermill": {
          "duration": 0.062246,
          "end_time": "2024-05-23T12:55:36.322271",
          "exception": false,
          "start_time": "2024-05-23T12:55:36.260025",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_dataset, val_dataset = dataset.train_test_split(\n",
        "    test_size=val_size,\n",
        "    train_size=train_size,\n",
        "    seed=42\n",
        ")['train'], dataset.train_test_split(\n",
        "    test_size=val_size,\n",
        "    train_size=train_size,\n",
        "    seed=42\n",
        ")['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964fa7b3",
      "metadata": {
        "id": "964fa7b3",
        "papermill": {
          "duration": 0.043236,
          "end_time": "2024-05-23T12:55:36.409124",
          "exception": false,
          "start_time": "2024-05-23T12:55:36.365888",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e05537f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:36.498340Z",
          "iopub.status.busy": "2024-05-23T12:55:36.497585Z",
          "iopub.status.idle": "2024-05-23T12:55:36.501783Z",
          "shell.execute_reply": "2024-05-23T12:55:36.500861Z"
        },
        "id": "4e05537f",
        "papermill": {
          "duration": 0.050703,
          "end_time": "2024-05-23T12:55:36.503729",
          "exception": false,
          "start_time": "2024-05-23T12:55:36.453026",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# model_name = \"meta-llama/Llama-2-7b-hf\"\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9176c48f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:36.592301Z",
          "iopub.status.busy": "2024-05-23T12:55:36.591706Z",
          "iopub.status.idle": "2024-05-23T12:55:36.733417Z",
          "shell.execute_reply": "2024-05-23T12:55:36.732376Z"
        },
        "id": "9176c48f",
        "outputId": "51bb2e17-336b-4b81-f879-f5c624daaa71",
        "papermill": {
          "duration": 0.18823,
          "end_time": "2024-05-23T12:55:36.735485",
          "exception": false,
          "start_time": "2024-05-23T12:55:36.547255",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "hf_token = \"Your_HuggingFace_Token\"\n",
        "\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a0a8e6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:55:36.826653Z",
          "iopub.status.busy": "2024-05-23T12:55:36.825933Z",
          "iopub.status.idle": "2024-05-23T12:58:05.828225Z",
          "shell.execute_reply": "2024-05-23T12:58:05.827381Z"
        },
        "id": "c3a0a8e6",
        "outputId": "77398aa6-0fac-4b5c-c432-54d98f48f9b3",
        "papermill": {
          "duration": 149.050064,
          "end_time": "2024-05-23T12:58:05.830541",
          "exception": false,
          "start_time": "2024-05-23T12:55:36.780477",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "6da12003e61c4a489fc8beae7c89b040",
            "75511a17e4fb4e0fb40f6c5bde712a31",
            "325b49d48ca344ea92d916683b2e698c",
            "ba1d20fa8b7945388c7e212b2d628483",
            "92a5fc10a5bd4e27ac387fb64a32e3b2",
            "3214a43ca5b74f17a6e6cd747249f095",
            "0496c8b5341e4c2095409eb6f08d93d3",
            "9d588266be984af5bc0a0490336b43bc",
            "eaa19191e9714a42a125bdf9d15f4c4e",
            "da46b04f97f1466c9d809fee36f15f0c",
            "657633cb48514a0496bca579a9739368",
            "06e85c155d314216a0d8e360b0acb5e8"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6da12003e61c4a489fc8beae7c89b040",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75511a17e4fb4e0fb40f6c5bde712a31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "325b49d48ca344ea92d916683b2e698c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba1d20fa8b7945388c7e212b2d628483",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92a5fc10a5bd4e27ac387fb64a32e3b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3214a43ca5b74f17a6e6cd747249f095",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0496c8b5341e4c2095409eb6f08d93d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d588266be984af5bc0a0490336b43bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaa19191e9714a42a125bdf9d15f4c4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da46b04f97f1466c9d809fee36f15f0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "657633cb48514a0496bca579a9739368",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06e85c155d314216a0d8e360b0acb5e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Function to create model and tokenizer\n",
        "def create_model_and_tokenizer():\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        use_safetensors=True,\n",
        "        quantization_config=bnb_config,\n",
        "        trust_remote_code=True,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"right\"\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "# Create model and tokenizer\n",
        "model, tokenizer = create_model_and_tokenizer()\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "452a81c0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:58:05.924663Z",
          "iopub.status.busy": "2024-05-23T12:58:05.923975Z",
          "iopub.status.idle": "2024-05-23T12:58:05.930478Z",
          "shell.execute_reply": "2024-05-23T12:58:05.929515Z"
        },
        "id": "452a81c0",
        "outputId": "08170fce-2a83-47c8-dc80-632bfa98c042",
        "papermill": {
          "duration": 0.055972,
          "end_time": "2024-05-23T12:58:05.932491",
          "exception": false,
          "start_time": "2024-05-23T12:58:05.876519",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
              " 'load_in_8bit': False,\n",
              " 'load_in_4bit': True,\n",
              " 'llm_int8_threshold': 6.0,\n",
              " 'llm_int8_skip_modules': None,\n",
              " 'llm_int8_enable_fp32_cpu_offload': False,\n",
              " 'llm_int8_has_fp16_weight': False,\n",
              " 'bnb_4bit_quant_type': 'nf4',\n",
              " 'bnb_4bit_use_double_quant': False,\n",
              " 'bnb_4bit_compute_dtype': 'float16'}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model quantization configuration\n",
        "model.config.quantization_config.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3991893",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:58:06.026519Z",
          "iopub.status.busy": "2024-05-23T12:58:06.025754Z",
          "iopub.status.idle": "2024-05-23T12:58:06.031455Z",
          "shell.execute_reply": "2024-05-23T12:58:06.030519Z"
        },
        "id": "c3991893",
        "papermill": {
          "duration": 0.055167,
          "end_time": "2024-05-23T12:58:06.033376",
          "exception": false,
          "start_time": "2024-05-23T12:58:05.978209",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define LoRA configuration\n",
        "lora_r = 16\n",
        "lora_alpha = 64\n",
        "lora_dropout = 0.1\n",
        "lora_target_modules = [\n",
        "    \"q_proj\",\n",
        "    \"up_proj\",\n",
        "    \"o_proj\",\n",
        "    \"k_proj\",\n",
        "    \"down_proj\",\n",
        "    \"gate_proj\",\n",
        "    \"v_proj\",\n",
        "]\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    target_modules=lora_target_modules,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77279b4b",
      "metadata": {
        "id": "77279b4b",
        "papermill": {
          "duration": 0.045698,
          "end_time": "2024-05-23T12:58:06.124920",
          "exception": false,
          "start_time": "2024-05-23T12:58:06.079222",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4892801a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:58:06.219911Z",
          "iopub.status.busy": "2024-05-23T12:58:06.219137Z",
          "iopub.status.idle": "2024-05-23T12:58:06.223587Z",
          "shell.execute_reply": "2024-05-23T12:58:06.222642Z"
        },
        "id": "4892801a",
        "papermill": {
          "duration": 0.054468,
          "end_time": "2024-05-23T12:58:06.225467",
          "exception": false,
          "start_time": "2024-05-23T12:58:06.170999",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = \"experiments\"\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir experiments/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c732875",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:58:06.322435Z",
          "iopub.status.busy": "2024-05-23T12:58:06.322074Z",
          "iopub.status.idle": "2024-05-23T12:58:06.362062Z",
          "shell.execute_reply": "2024-05-23T12:58:06.361066Z"
        },
        "id": "2c732875",
        "papermill": {
          "duration": 0.091151,
          "end_time": "2024-05-23T12:58:06.364172",
          "exception": false,
          "start_time": "2024-05-23T12:58:06.273021",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Our training arguments\n",
        "training_arguments = TrainingArguments(\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    logging_steps=1,\n",
        "    learning_rate=1e-4,\n",
        "    fp16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    num_train_epochs=3, # was 1 and 2\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    warmup_ratio=0.05,\n",
        "    save_strategy=\"epoch\",\n",
        "    group_by_length=True,\n",
        "    output_dir=\"experiments\",\n",
        "    # report_to=\"tensorboard\",\n",
        "    save_safetensors=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de768cee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:58:06.459026Z",
          "iopub.status.busy": "2024-05-23T12:58:06.458415Z",
          "iopub.status.idle": "2024-05-23T12:59:15.936221Z",
          "shell.execute_reply": "2024-05-23T12:59:15.935394Z"
        },
        "id": "de768cee",
        "outputId": "60d5af02-5d84-4b08-b56a-18c639c22ed2",
        "papermill": {
          "duration": 69.527004,
          "end_time": "2024-05-23T12:59:15.938655",
          "exception": false,
          "start_time": "2024-05-23T12:58:06.411651",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "0b1a9bdcbd9f44f1b2442a46fee0aa41",
            "14e92be547f14becbcf59400ee094cf8"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b1a9bdcbd9f44f1b2442a46fee0aa41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2576 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14e92be547f14becbcf59400ee094cf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize SFTTrainer that will train our model\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"ad_text\",\n",
        "    max_seq_length=4096,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "411d3f99",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:59:16.036578Z",
          "iopub.status.busy": "2024-05-23T12:59:16.035822Z",
          "iopub.status.idle": "2024-05-23T12:59:19.219529Z",
          "shell.execute_reply": "2024-05-23T12:59:19.218366Z"
        },
        "papermill": {
          "duration": 3.236097,
          "end_time": "2024-05-23T12:59:19.221895",
          "exception": false,
          "start_time": "2024-05-23T12:59:15.985798",
          "status": "completed"
        },
        "tags": [],
        "id": "411d3f99",
        "outputId": "17a02088-5bdc-4094-d8d5-74684eac1ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n"
          ]
        }
      ],
      "source": [
        "# !wandb login Your_Wandb_Token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33349dad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T12:59:19.333666Z",
          "iopub.status.busy": "2024-05-23T12:59:19.333231Z",
          "iopub.status.idle": "2024-05-23T14:34:36.042795Z",
          "shell.execute_reply": "2024-05-23T14:34:36.041809Z"
        },
        "id": "33349dad",
        "outputId": "cccd6a52-2048-4b32-ebb9-2a4cb8cd5f11",
        "papermill": {
          "duration": 5716.764665,
          "end_time": "2024-05-23T14:34:36.044758",
          "exception": false,
          "start_time": "2024-05-23T12:59:19.280093",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgencgeray\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240523_125921-s2dcyk27\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtoasty-haze-86\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/gencgeray/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/gencgeray/huggingface/runs/s2dcyk27\u001b[0m\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='483' max='483' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [483/483 1:34:13, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.591100</td>\n",
              "      <td>2.612150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.467800</td>\n",
              "      <td>2.619116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.978700</td>\n",
              "      <td>2.388678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.556900</td>\n",
              "      <td>2.469529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=483, training_loss=2.2517564837236583, metrics={'train_runtime': 5715.8597, 'train_samples_per_second': 1.352, 'train_steps_per_second': 0.085, 'total_flos': 1.1062444932562944e+16, 'train_loss': 2.2517564837236583, 'epoch': 3.0})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ed3940",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T14:34:36.146839Z",
          "iopub.status.busy": "2024-05-23T14:34:36.146533Z",
          "iopub.status.idle": "2024-05-23T14:34:36.806509Z",
          "shell.execute_reply": "2024-05-23T14:34:36.805488Z"
        },
        "id": "42ed3940",
        "papermill": {
          "duration": 0.711005,
          "end_time": "2024-05-23T14:34:36.808615",
          "exception": false,
          "start_time": "2024-05-23T14:34:36.097610",
          "status": "completed"
        },
        "tags": [],
        "outputId": "3a123c4a-2ec4-4832-fcfe-f76cb7b369de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('experiments/tokenizer_config.json',\n",
              " 'experiments/special_tokens_map.json',\n",
              " 'experiments/tokenizer.json')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the trained model\n",
        "# from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "# trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "#     OUTPUT_DIR,\n",
        "#     low_cpu_mem_usage=True,\n",
        "# )\n",
        "\n",
        "# merged_model = model.merge_and_unload()\n",
        "# merged_model.save_pretrained(\"merged_model\", safe_serialization=True)\n",
        "# tokenizer.save_pretrained(\"merged_model\")\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2433b50",
      "metadata": {
        "id": "f2433b50",
        "papermill": {
          "duration": 0.046673,
          "end_time": "2024-05-23T14:34:37.210937",
          "exception": false,
          "start_time": "2024-05-23T14:34:37.164264",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Inference example with the Fine-tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07175337",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T14:34:37.002863Z",
          "iopub.status.busy": "2024-05-23T14:34:37.002488Z",
          "iopub.status.idle": "2024-05-23T14:34:37.012111Z",
          "shell.execute_reply": "2024-05-23T14:34:37.011130Z"
        },
        "id": "07175337",
        "papermill": {
          "duration": 0.061746,
          "end_time": "2024-05-23T14:34:37.014120",
          "exception": false,
          "start_time": "2024-05-23T14:34:36.952374",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define function to generate prompt for inference\n",
        "def generate_prompt(conversation: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
        "    return f\"\"\"### Instruction: {system_prompt}\n",
        "\n",
        "### Input:\n",
        "{conversation.strip()}\n",
        "\n",
        "### Response:\n",
        "\"\"\".strip()\n",
        "\n",
        "def clean_generated_text(text: str) -> str:\n",
        "    # Remove duplicate hashtags\n",
        "    hashtags = set()\n",
        "    cleaned_text = []\n",
        "    for word in text.split():\n",
        "        if word.startswith(\"#\"):\n",
        "            if word.lower() not in hashtags:\n",
        "                hashtags.add(word.lower())\n",
        "                cleaned_text.append(word)\n",
        "        else:\n",
        "            cleaned_text.append(word)\n",
        "    return \" \".join(cleaned_text)\n",
        "\n",
        "# Define function to generate post\n",
        "def generate_post(model, text: str):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    inputs_length = len(inputs[\"input_ids\"][0])\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs,\n",
        "                                 max_new_tokens=100,\n",
        "                                 temperature=0.7,\n",
        "                                 top_p=0.95)\n",
        "    generated_text = tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True)\n",
        "    return clean_generated_text(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6a0720",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-23T14:34:37.308005Z",
          "iopub.status.busy": "2024-05-23T14:34:37.307657Z",
          "iopub.status.idle": "2024-05-23T14:35:37.424381Z",
          "shell.execute_reply": "2024-05-23T14:35:37.423302Z"
        },
        "id": "8b6a0720",
        "papermill": {
          "duration": 60.217166,
          "end_time": "2024-05-23T14:35:37.476166",
          "exception": false,
          "start_time": "2024-05-23T14:34:37.259000",
          "status": "completed"
        },
        "tags": [],
        "outputId": "aadeb1cc-dfdd-4f75-ae63-d2fdde2ee411"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Post Content:\n",
            " 📸: 1-2 of you posing in front of a mountain range or holding your packs on a summit 🎒: 1 in hand, 1 on your back 🗺️: 1 showing the route you took, 1 showing the summit you reached. #OspreyPacks #Adventure #Climbing #Backpacking #Backpack #Osprey #Backcountry #SeeYouOutHere #SeeYouOutHere2023\n"
          ]
        }
      ],
      "source": [
        "# Test the function with a sample instruction\n",
        "sample_instruction = \"Create a new post about the 'Adventure' model backpack with 25 liters capacity for $200, perfect for climbers.\"\n",
        "prompt = generate_prompt(sample_instruction)\n",
        "generated_post = generate_post(model, prompt)\n",
        "print(\"Generated Post Content:\\n\", generated_post)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we covered the process of fine-tuning a Meta-LLaMA model using the Hugging Face Transformers library and specific configurations for optimization. Some of the key steps in the notebook are:\n",
        "\n",
        "1. **Data Preparation**:\n",
        "   - Loading and preprocessing Instagram posts data.\n",
        "   - Generating conversation texts and training prompts from the dataset.\n",
        "\n",
        "2. **Model Configuration**:\n",
        "   - Initializing the LLaMA model with a specific tokenizer.\n",
        "   - Configuring model quantization to optimize for memory usage.\n",
        "   - Setting up Low-Rank Adaptation (LoRA) for fine-tuning specific parts of the model.\n",
        "\n",
        "3. **Training**:\n",
        "   - Defining training arguments such as batch size, learning rate, and evaluation strategy.\n",
        "   - Training the model using the prepared dataset and configurations.\n",
        "   - Saving the trained model and tokenizer.\n",
        "\n",
        "4. **Inference**:\n",
        "   - Setting up a function to generate prompts for the model.\n",
        "   - Defining a function to generate responses from the model.\n"
      ],
      "metadata": {
        "id": "F-8uIGkk4DtD"
      },
      "id": "F-8uIGkk4DtD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "- [Fine-tuning Llama 2 on Your Own Dataset | Train an LLM for Your Use Case with QLoRA on a Single GPU](https://www.youtube.com/watch?v=MDA3LUKNl1E)\n",
        "- https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct"
      ],
      "metadata": {
        "id": "CQXOFosx3ALI"
      },
      "id": "CQXOFosx3ALI"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5056051,
          "sourceId": 8477664,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 6259.089031,
      "end_time": "2024-05-23T14:35:41.180713",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-05-23T12:51:22.091682",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}